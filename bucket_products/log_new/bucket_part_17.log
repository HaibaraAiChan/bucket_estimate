 the number of batches:  17
the ratio of the output nids to be processed:  0.9328843013465873
weights list of these nids:  [0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.054875846386293, 0.05487075916589934]
check_connections_block*********************************
num of batch  17
check_connections_block*********************************
generate_K_hop_neighbors time  57.553128480911255
7.9986881568942705
7.993897313089989
8.003903049020213
7.981960803950507
7.94385058882944
7.986435867089723
8.00376771444947
7.983124681258891
8.002603837141084
8.00051968475165
7.961615506815562
7.98023754374972
7.996396491496365
7.978929309565877
7.987798235101864
8.035526227050358
7.987347751410656
the split redundant ratio 
[7.9986881568942705, 7.993897313089989, 8.003903049020213, 7.981960803950507, 7.94385058882944, 7.986435867089723, 8.00376771444947, 7.983124681258891, 8.002603837141084, 8.00051968475165, 7.961615506815562, 7.98023754374972, 7.996396491496365, 7.978929309565877, 7.987798235101864, 8.035526227050358, 7.987347751410656]
17
capacity est:  0.41788328797037977
capacity  393
sorted_dict  {23: 393, 22: 386, 21: 357, 20: 325, 18: 297, 19: 291, 17: 277, 16: 261, 15: 251, 14: 245, 13: 236, 12: 210, 10: 178, 11: 175, 9: 159, 8: 130, 7: 109, 6: 102, 5: 78, 4: 54, 3: 40, 2: 24, 1: 10, 0: 4}

weights after sort [393, 386, 357, 325, 297, 291, 277, 261, 251, 245, 236, 210, 178, 175, 159, 130, 109, 102, 78, 54, 40, 24, 10, 4]

remove bucket_id:  [0]
original bucket_id :,  [23]
remove weights:  [393],                 ------------sum 393

before remove weights,  [393, 386, 357, 325, 297, 291, 277, 261, 251, 245, 236, 210, 178, 175, 159, 130, 109, 102, 78, 54, 40, 24, 10, 4]
after remove pre pack weights,  [386, 357, 325, 297, 291, 277, 261, 251, 245, 236, 210, 178, 175, 159, 130, 109, 102, 78, 54, 40, 24, 10, 4]

remove bucket_id:  [4, 16]
original bucket_id :,  [19, 6]
remove weights:  [291 102],             ------------sum 393

before remove weights,  [386, 357, 325, 297, 291, 277, 261, 251, 245, 236, 210, 178, 175, 159, 130, 109, 102, 78, 54, 40, 24, 10, 4]
after remove pre pack weights,  [386, 357, 325, 297, 277, 261, 251, 245, 236, 210, 178, 175, 159, 130, 109, 78, 54, 40, 24, 10, 4]

remove bucket_id:  [5, 15, 16]
original bucket_id :,  [16, 5, 4]
remove weights:  [261  78  54],                 ------------sum 393

before remove weights,  [386, 357, 325, 297, 277, 261, 251, 245, 236, 210, 178, 175, 159, 130, 109, 78, 54, 40, 24, 10, 4]
after remove pre pack weights,  [386, 357, 325, 297, 277, 251, 245, 236, 210, 178, 175, 159, 130, 109, 40, 24, 10, 4]

remove bucket_id:  [9, 10, 14]
original bucket_id :,  [10, 11, 3]
remove weights:  [178 175  40],                 ------------sum 393

before remove weights,  [386, 357, 325, 297, 277, 251, 245, 236, 210, 178, 175, 159, 130, 109, 40, 24, 10, 4]
after remove pre pack weights,  [386, 357, 325, 297, 277, 251, 245, 236, 210, 159, 130, 109, 24, 10, 4]

remove bucket_id:  [8, 9, 12]
original bucket_id :,  [12, 9, 2]
remove weights:  [210 159  24],                 ------------sum 393

before remove weights,  [386, 357, 325, 297, 277, 251, 245, 236, 210, 159, 130, 109, 24, 10, 4]
after remove pre pack weights,  [386, 357, 325, 297, 277, 251, 245, 236, 130, 109, 10, 4]

remove bucket_id:  [5, 8, 10]
original bucket_id :,  [15, 8, 1]
remove weights:  [251 130  10],                 ------------sum 391

before remove weights,  [386, 357, 325, 297, 277, 251, 245, 236, 130, 109, 10, 4]
after remove pre pack weights,  [386, 357, 325, 297, 277, 245, 236, 109, 4]

remove bucket_id:  [0, 8]
original bucket_id :,  [22, 0]
remove weights:  [386   4],             ------------sum 390

before remove weights,  [386, 357, 325, 297, 277, 245, 236, 109, 4]
after remove pre pack weights,  [357, 325, 297, 277, 245, 236, 109]

remove bucket_id:  [3, 6]
original bucket_id :,  [17, 7]
remove weights:  [277 109],             ------------sum 386

before remove weights,  [357, 325, 297, 277, 245, 236, 109]
after remove pre pack weights,  [357, 325, 297, 245, 236]

remove bucket_id:  [0]
original bucket_id :,  [21]
remove weights:  [357],                 ------------sum 357

before remove weights,  [357, 325, 297, 245, 236]
after remove pre pack weights,  [325, 297, 245, 236]

remove bucket_id:  [0]
original bucket_id :,  [20]
remove weights:  [325],                 ------------sum 325

before remove weights,  [325, 297, 245, 236]
after remove pre pack weights,  [297, 245, 236]

remove bucket_id:  [0]
original bucket_id :,  [18]
remove weights:  [297],                 ------------sum 297

before remove weights,  [297, 245, 236]
after remove pre pack weights,  [245, 236]

remove bucket_id:  [0]
original bucket_id :,  [14]
remove weights:  [245],                 ------------sum 245

before remove weights,  [245, 236]
after remove pre pack weights,  [236]
the last batch value is  236
G_BUCKET_ID_list [[23], [19, 6], [16, 5, 4], [10, 11, 3], [12, 9, 2], [15, 8, 1], [22, 0], [17, 7], [21], [20], [18], [14], [13]]
G_BUCKET_ID_list length 13
split_batches_nid_list  17
../../pytorch/bucketing/bucket_partitioner.py:251: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  tensor_group = torch.tensor(g_bucket_nids_list[j], dtype=torch.long)
the length of split_batches_nid_list  17
len local_batched_seeds_list  17
 the number of batches:  17
check_connections_block*********************************
num of batch  17
check_connections_block*********************************
Nvidia-smi: 1.34375 GB
    Memory Allocated: 0.000934600830078125  GigaBytes
Max Memory Allocated: 0.000934600830078125  GigaBytes

batch 0
src global  913376
seeds global  11435
----------------------------------------after load_block_subtensor
 Nvidia-smi: 1.685546875 GB
    Memory Allocated: 0.3412790298461914  GigaBytes
Max Memory Allocated: 0.3412790298461914  GigaBytes

----------------------------------------after blocks to device
 Nvidia-smi: 1.79296875 GB
    Memory Allocated: 0.3607754707336426  GigaBytes
Max Memory Allocated: 0.3607754707336426  GigaBytes

----------------------------------------after model forward
 Nvidia-smi: 17.62890625 GB
    Memory Allocated: 15.758827686309814  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after loss_fcn calculation
 Nvidia-smi: 17.62890625 GB
    Memory Allocated: 15.761394500732422  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after loss backward
 Nvidia-smi: 17.63671875 GB
    Memory Allocated: 0.38822221755981445  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

---------------------------------------- batch 0
 Nvidia-smi: 17.63671875 GB
    Memory Allocated: 0.38822221755981445  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

batch 1
src global  913805
seeds global  11921
----------------------------------------after load_block_subtensor
 Nvidia-smi: 17.63671875 GB
    Memory Allocated: 0.3528103828430176  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after blocks to device
 Nvidia-smi: 17.63671875 GB
    Memory Allocated: 0.37233972549438477  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after model forward
 Nvidia-smi: 18.4921875 GB
    Memory Allocated: 15.74826431274414  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after loss_fcn calculation
 Nvidia-smi: 18.4921875 GB
    Memory Allocated: 15.750352382659912  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after loss backward
 Nvidia-smi: 18.4921875 GB
    Memory Allocated: 0.39601707458496094  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

---------------------------------------- batch 1
 Nvidia-smi: 18.4921875 GB
    Memory Allocated: 0.39601707458496094  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

batch 2
src global  913928
seeds global  12302
----------------------------------------after load_block_subtensor
 Nvidia-smi: 18.4921875 GB
    Memory Allocated: 0.3614192008972168  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after blocks to device
 Nvidia-smi: 18.4921875 GB
    Memory Allocated: 0.3804030418395996  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after model forward
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 15.739403247833252  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after loss_fcn calculation
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 15.742264747619629  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after loss backward
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 0.4031796455383301  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

---------------------------------------- batch 2
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 0.4031796455383301  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

batch 3
src global  912963
seeds global  12425
----------------------------------------after load_block_subtensor
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 0.36835145950317383  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after blocks to device
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 0.38733577728271484  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after model forward
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 15.743496894836426  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after loss_fcn calculation
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 15.74580717086792  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after loss backward
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 0.4104933738708496  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

---------------------------------------- batch 3
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 0.4104933738708496  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

batch 4
src global  915923
seeds global  12167
----------------------------------------after load_block_subtensor
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 0.37682151794433594  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after blocks to device
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 0.3957853317260742  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after model forward
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 15.728378772735596  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after loss_fcn calculation
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 15.73075819015503  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after loss backward
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 0.4199376106262207  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

---------------------------------------- batch 4
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 0.4199376106262207  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

batch 5
src global  919898
seeds global  12145
----------------------------------------after load_block_subtensor
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 0.3868074417114258  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after blocks to device
 Nvidia-smi: 18.505859375 GB
    Memory Allocated: 0.40652942657470703  GigaBytes
Max Memory Allocated: 16.019275665283203  GigaBytes

----------------------------------------after model forward
 Nvidia-smi: 18.603515625 GB
    Memory Allocated: 15.833943367004395  GigaBytes
Max Memory Allocated: 16.095786571502686  GigaBytes

----------------------------------------after loss_fcn calculation
 Nvidia-smi: 18.603515625 GB
    Memory Allocated: 15.836462497711182  GigaBytes
Max Memory Allocated: 16.095786571502686  GigaBytes

----------------------------------------after loss backward
 Nvidia-smi: 18.60546875 GB
    Memory Allocated: 0.4306778907775879  GigaBytes
Max Memory Allocated: 16.095786571502686  GigaBytes

---------------------------------------- batch 5
 Nvidia-smi: 18.60546875 GB
    Memory Allocated: 0.4306778907775879  GigaBytes
Max Memory Allocated: 16.095786571502686  GigaBytes

batch 6
src global  1813942
seeds global  183970
----------------------------------------after load_block_subtensor
 Nvidia-smi: 18.60546875 GB
    Memory Allocated: 0.7306733131408691  GigaBytes
Max Memory Allocated: 16.095786571502686  GigaBytes

----------------------------------------after blocks to device
 Nvidia-smi: 18.60546875 GB
    Memory Allocated: 0.851107120513916  GigaBytes
Max Memory Allocated: 16.095786571502686  GigaBytes

Traceback (most recent call last):
  File "AA_mem_25_split.py", line 375, in <module>
    main()
  File "AA_mem_25_split.py", line 371, in main
    best_test = run(args, device, data)
  File "AA_mem_25_split.py", line 205, in run
    batch_pred = model(blocks, batch_inputs)#------------*
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "../../pytorch/models/graphsage_model_wo_mem.py", line 183, in forward
    x = layer(block, x)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "../../pytorch/models/graphsage_model_wo_mem.py", line 129, in forward
    graph.update_all(msg_fn, self._lstm_reducer)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/heterograph.py", line 4895, in update_all
    ndata = core.message_passing(g, message_func, reduce_func, apply_node_func)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 372, in message_passing
    ndata = invoke_udf_reduce(g, rfunc, msgdata, orig_nid=orig_nid)
  File "/home/cc/.local/lib/python3.6/site-packages/dgl/core.py", line 143, in invoke_udf_reduce
    bkt_rsts.append(func(nbatch))
  File "../../pytorch/models/graphsage_model_wo_mem.py", line 75, in _lstm_reducer
    _, (rst, _) = self.lstm(m, h)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/cc/.local/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 680, in forward
    self.dropout, self.training, self.bidirectional, self.batch_first)
RuntimeError: CUDA out of memory. Tried to allocate 1.65 GiB (GPU 0; 23.65 GiB total capacity; 18.68 GiB already allocated; 830.31 MiB free; 21.31 GiB reserved in total by PyTorch)